# -*- coding: utf-8 -*-
"""CareerCompassMLmodel.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/gist/Jai-Pradhiksha/fb5c1eaf8f6620e8ee1794a4772ea616/careercompass.ipynb
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

df = pd.read_csv('linkedin.csv')
find_company = 'Sw iggy'
find_location = 'BENgaluru  '
find_title = 'Product'
find_company = find_company.lower().replace(" ","")
find_location = find_location.lower().replace(" ","")
find_title = find_title.lower().replace(" ","")
find = (df['company'].str.lower().str.contains(find_company)) & (df['location'].str.lower().str.contains(find_location)) & (df['title'].str.lower().str.contains(find_title))
result = df[find]
print("The number of jobs you can give a try : ",result['title'].count())
print(result)

df = pd.read_csv('skillscsv.csv')
find_skill = 'EDITING'
find_skill = find_skill.lower().replace(" ","")
find = (df['skills'].str.lower().str.contains(find_skill))
result = df[find]
print("The number of jobs you can give a try : ",result['title'].count())
print(result)

import nltk
from nltk.corpus import wordnet

pip install nltk

import nltk
nltk.download('all')
#from nltk.corpus import wordnet

synonyms = []
for syn in wordnet.synsets('Computer'):
  for lemma in syn.lemmas():
    synonyms.append(lemma.name())
print(synonyms)

syn = wordnet.synsets('Computer')
print(syn[0].definition())

antonyms = []
for syn in wordnet.synsets('small'):
  for lemma in syn.lemma():
    if lemma.antonyms():
      antonyms.append(lemma.antonyms()[0].name())
print(antonyms)

import pandas as pd

# Load data from CSV file
linkedin_data = pd.read_csv('skillscsv.csv')

import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

df = pd.read_csv('skillscsv.csv')
df['skills'].fillna('', inplace=True)
df['text'] = df['title'] + ' ' + df['company'] + ' ' + df['location'] + ' ' + df['skills']
tfidf_vectorizer = TfidfVectorizer(stop_words='english')
tfidf_matrix = tfidf_vectorizer.fit_transform(df['text'])
input_skills = ["python", "machine learning", "data analysis"]

input_skills_vector = tfidf_vectorizer.transform([' '.join(input_skills)])
cosine_sim = cosine_similarity(input_skills_vector, tfidf_matrix)
num_recommendations = 5
top_indices = cosine_sim.argsort()[0][-num_recommendations:][::-1]

recommended_jobs = df.iloc[top_indices][['title', 'company', 'location']]
print("Recommended Jobs:")
print(recommended_jobs)

import sys
import csv
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

if len(sys.argv) < 2:
    print("Please enter atleast 3 skills")
    sys.exit(1)

find_skill = sys.argv[1:]

df = pd.read_csv('skillscsv.csv')
for i in range(len(find_skill)):
  find = (df['skills'].str.lower().str.contains(find_skill[i]))

result = df[find]

if(result['title'].count()!=0):
  print("The number of jobs you can give a try : ",result['title'].count())
  print(result)

#Recommendation
df['skills'].fillna('', inplace=True)
df['text'] = df['title'] + ' ' + df['company'] + ' ' + df['location'] + ' ' + df['skills']
tfidf_vectorizer = TfidfVectorizer(stop_words='english')
tfidf_matrix = tfidf_vectorizer.fit_transform(df['text'])

input_skills = find_skill

input_skills_vector = tfidf_vectorizer.transform([' '.join(input_skills)])
cosine_sim = cosine_similarity(input_skills_vector, tfidf_matrix)
num_recommendations = 5
top_indices = cosine_sim.argsort()[0][-num_recommendations:][::-1]

recommended_jobs = df.iloc[top_indices][['title', 'company', 'location']]
print("Recommended Jobs :")
print(recommended_jobs)